---
layout: post
title: Data Visualization Processing the MoMA Collection
description: Pandas, Plotly, Regular Expression
image: assets/images/pic_makerspace05.jpg
---
<hr />
## Project Description
This data visualization module is inspired by MoMA's [data dump](https://github.com/MuseumofModernArt/collection) in 2015. MoMA had release the database of their collection which contains over 130,000 pieces of artwork over the timespan of 150 years. In this session, we will learn to visualise MoMA collection similar to what [Oliver Roeder](https://fivethirtyeight.com/features/a-nerds-guide-to-the-2229-paintings-at-moma/) had done at [FiveThirtyEight](https://fivethirtyeight.com/), perhaps we will even take it further. This session will allow us to dive into Pandas, Plot.ly, and python regular expression a lot more and get into some of the more intermediate level of data processing. In the course this this workshop, we will try to re-create some of Oliver's visualizations such as these.

<iframe width="800" height="500" frameborder="0" scrolling="no" src="//plot.ly/~prattitl/60.embed"></iframe>

<iframe width="800" height="500" frameborder="0" scrolling="no" src="//plot.ly/~prattitl/58.embed"></iframe>

***

# Step 1
###Import Libraries and Data

This workshop module assumes you have already installed all the necessary python libraries, if you have not done so, please go back to the previous module. What we will need for this session is Plotly and Pandas, and we will run the entire session on Jupyter.  

First import all the libraries by executing the following code.

<pre><code>import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, iplot
from collections import defaultdict
import pandas as pd

init_notebook_mode(connected = True)
</code></pre>

Import the csv file by executing the following code.

<pre><code>df_moma = pd.read_csv('https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv')
</code></pre>

If you want to speed things up a little, download the csv file to your local drive and place it in the same folder as where you're running Jupyter Notebook, then execute this code.

<pre><code>df_moma = pd.read_csv('./Artworks.csv')
</code></pre>

Execute **df_moma** to see what's inside this variable.

![NaN](../../../assets/images/pic_moma_nan.jpg){:height="50%" width="50%"}

Upon inspecting the data, you should see that there're large number of records that has the value of **NaN**, which in computer science lingo means **"not a number"**, which also means there is an invalid record in the dataset. So before we begin to do anything beyond this, we need to for fill those records up with something else other than a **NaN** because it will cause issues with Pandas and Python down the line. We use a function call **fillna** to replace any **NaN** value with something we desinate.

<pre><code>df_moma[['Artist','Nationality','BeginDate',
         'Gender','Medium']] = df_moma[['Artist','Nationality','BeginDate',
                                        'Gender','Medium']].fillna(value='Unknown')</code></pre>

This line of code lets us look into each of these columns and find any **NaN** values and replace them with the word **"Unknown"**. We're now ready to move forward with more advanced date processing techniques.

# Step 2
### Data Processing

Now that we have imported the whole 130,000 records of MoMA's collection, say we want to see which is their largest collection, we can do something like - look at every record and see what "Medium" it uses and count them all. And finally give me a sorted result which tells me what is their biggest collection is based on the Medium.

To do this we need to call a **Function** that allows us to track duplicates. We have used this in previous sessions and it looks something like this. Type the following in and execute.

<pre><code>def list_duplicates(seq):
    tally = defaultdict(list)
    for i, item in enumerate(seq):
        tally[item].append(i)
    return((key,locs) for key, locs in tally.items() if len(locs)>0)</code></pre>

At this point, it's ok if you don't know how this function works. There're quite a bit of short form writing in there so it's a bit harder to read than usual. For now, treat it like a blackbox or a copy / paste button where you know exactly what it does and what you need to do to call the function. For more information on Python Functions, click the following for a deep dive into the subject. 

<div class="6u 12u$(small)">
	<ul class="actions vertical">
		<li><a href="https://www.w3schools.com/python/python_functions.asp" class="button special fit">Deep Dive: Python Functions</a></li>
	</ul>
</div>

Now let's call the function and have it list all the unique art media in the collection. 

<pre><code>medium = []
for dup in sorted(list_duplicates(df_moma['Medium'].astype(str))):
    medium.append([dup[0], len(dup[1])])
labels = ['Medium', 'Number Of Artwork']
df_medium = pd.DataFrame.from_records(medium, columns=labels)</code></pre>

First you need to create an empty list to store all the items being found. The next line is a bit complex, it first passes the column with header **['Medium']** to the function while ensuring it's passed as a **string**. The function sends back with a list of lists, first listing all the unique medium names, and then the row number in which the medium name had been found. So we just need to store all that information into the **medium** variable. `(dup[1])` is a list of all the row numbers where the medium is found, `len(dup[1])` is the **length** of that list, which essentially tells me how many times that medium is found in the collection.

Next we give the new list a label and create a new Pandas DataFrame for it. So now when you type in the following, you can show the dataframe and have it be sorted at the same time.

<pre><code>df_medium.sort_values('Number Of Artwork', ascending=False)
</code></pre>

![test image size](../../../assets/images/pic_moma_mediumsortedlist.jpg){:height="50%" width="50%"}

So now we know the largest collection MoMA has is photography and a large number of artwork have unknown media type.

Now let's say you want to look for specific **keywords** in the collection that you would associate with paintings, you can do something like this.

<pre><code>searchfor = ['paint','oil','canvas','Casein']
df_medium[df_medium['Medium'].str.contains('|'.join(searchfor))]</code></pre>

<div class="6u 12u$(small)">
	<ul class="actions vertical">
		<li><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html" class="button special fit">Deep Dive: Pandas Str Contains</a></li>
	</ul>
</div>

![test image size](../../../assets/images/pic_moma_mediumstrcontains.jpg){:height="50%" width="50%"}

Now combine the sort function with the search function and write it all at once.

<pre><code>df_medium[df_medium['Medium'].str.contains('|'.join(searchfor))].sort_values('Number Of Artwork', ascending=False)
</code></pre>

![test image size](../../../assets/images/pic_moma_mediumstrcontainssorted.jpg){:height="50%" width="50%"}

Now let's try to use the same method of finding duplicates to see which artist has the largest number of work at MoMA.

<pre><code>artists = []
for dup in sorted(list_duplicates(df_moma['Artist'].astype(str))):
    artists.append([dup[0], len(dup[1]), 
                    df_moma.loc[dup[1][0]]['Nationality'],
                    df_moma.loc[dup[1][0]]['BeginDate'],
                    df_moma.loc[dup[1][0]]['EndDate'],
                    df_moma.loc[dup[1][0]]['Gender'],
                    df_moma.loc[dup[1][0]]['Classification']])

labels = ['Artist', 'Number Of Artwork', 'Nationality', 'BirthYear', 'DeathYear', 'Gender','Classification']
df_artists = pd.DataFrame.from_records(artists, columns=labels)
df_artists.sort_values('Number Of Artwork', ascending=False)</code></pre>

![test image size](../../../assets/images/pic_moma_artistworksorted.jpg){:height="50%" width="50%"}

We can also single out individual artist and look at the variety of work based on medium.

<pre><code>df_picasso = df_moma[df_moma['Artist']=='Pablo Picasso']
picasso = []
for dup in sorted(list_duplicates(df_picasso['Medium'].astype(str))):
    picasso.append([dup[0], len(dup[1])])

labels = ['Type of Work', 'Number Of Artwork']
df_picassoWork = pd.DataFrame.from_records(picasso, columns=labels)
df_picassowork.sort_values('Number Of Artwork', ascending=False)</code></pre>


![test image size](../../../assets/images/pic_moma_picassomediumsorted.jpg){:height="50%" width="50%"}

So it turns out, MoMA has over one thousand pieces of art work by Picasso and almost 25% of that are litographic work!
***


# Step 3
### Date Created VS Date Aquired
We are diving deeper and deeper into data processing with Pandas as we continue to work with the same data set. This next exercise will dive right into one of the graphs 
[Oliver Roeder](https://fivethirtyeight.com/features/a-nerds-guide-to-the-2229-paintings-at-moma/) had done at [FiveThirtyEight](https://fivethirtyeight.com/) in which he graphed the year in which a painting had been painted versus the year in which the painted had been acquired by MoMA. It's a simple idea but to actually create this graph, it's anything but simple. We will have to rely on everything we have learned so far and more!

Let's open up a new notebook start fresh, and import the following packages.

<pre><code>import plotly.plotly as py
import plotly.graph_objs as go
from plotly.offline import download_plotlyjs, init_notebook_mode, iplot
from collections import defaultdict
import pandas as pd
import re, datetime

init_notebook_mode(connected = True)</code></pre>

Import the CSV file as we did before, again, your choice if you want to load it remotely or locally.

<pre><code>df_moma = pd.read_csv('https://github.com/MuseumofModernArt/collection/blob/master/Artworks.csv')
</code></pre>

<pre><code>df_moma = pd.read_csv('./Artworks.csv')
</code></pre>

And again, let's clean up all the missing values which is represented by **NaN** and fill that with the text **Unknown**. For more on how to work with **Missing Data** in Pandas, click here.

<div class="6u 12u$(small)">
	<ul class="actions vertical">
		<li><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html" class="button special fit">Deep Dive: Pandas Missing Data</a></li>
	</ul>
</div>

<pre><code>df_moma[['Artist','Nationality','Date','BeginDate','Gender','DateAcquired']] = df_moma[['Artist','Nationality','Date','BeginDate','Gender','DateAcquired']].fillna(value='Unknown')
</code></pre>

Now let's look at the 2 column of data we're interested in working with, DateAcquired and Date.

<pre><code>df_moma[['DateAcquired','Date']]
</code></pre>

<iframe width="900" height="800" frameborder="0" scrolling="no" src="//plot.ly/~prattitl/83.embed"></iframe>

***

# Step 3
### Launch Jupyter Notebook
Next, we first create a folder where all the coding files will reside. In my case I'll create a folder on my desktop call dataviz. You can do that however you want. Once the folder has been created, go back to your Terminal or Anaconda Prompt, then type cd and then the path to your newly created folder. *If you don't like typing the full path of your folder by hand, follow this tip.



***


# Step 4
### Webscraping & Dataprocessing
Webscraping is a very powerful tool for data visualization especially if you're interested in culturo-socio-polico-economic issues. This tool allows you to tap into vast amount of data from sometimes not so data friendly sources. In this example, we will look at salay levels of people who work in the New York Public Education System. By deploying the Freedom of Information Act, many organizations have requested and released data such as salary levels of all public employees across the country. This is an invaluable tool to demand accountability for people holding public offices. However, these dataset do not always come in a format that is ready to be visualized. In our case, we will use the data released by the [Empire Center](https://www.seethroughny.net/) looking at salary levels of employees working in the CUNY system.



***

# Step 5
### Data Visualizaiton
Finally we're ready to visualize the data. As you can see, the table only has 4 columns of data and 2 of which are identical. So essentially, we only have **names** and **salary** to work with. So essentially we can do a [Box Plot](https://plot.ly/python/box-plots/) that allow us to look at a 1-Dimensional data in an interesting way.



***

# Summary

### What You have Learned

* How to create and assign value to a variable
* How to create and assign values a list
* How to create and assign values a list of lists
* How to bring data into Python as text or csv files 
* How to create and use a counter
* How to write a basic function
* How to call a basic function
* Basic loop structure - how to use for-loops
* How to import packages in Python
* How to use basic functions of packages like Pandas, Plotly, BeautifulSoup
* How to create interactive plots with Plotly.