---
layout: post
title: Data Visualization Round 1
description: First set of sound measurements conducted on Jan 30
image: assets/images/pic_python.jpg
---
<hr />
<h2>Project Description</h2>
This workshop is our first introduction to data visualization with Python. No programming background is required. In this first workshop you will learn to setup Python programming environment and all the related programming packages, and you will end with a fairly straight forward webscraping exercise to visualize the income level of the University of Virginia School of Architecture Faculty. By the end of this session, you will learn to do something like this.

<iframe width="1024" height="550" frameborder="0" scrolling="no" src="//plot.ly/~tngai/6.embed"></iframe>

<hr />

<h1>Step 1</h1>
<h3>Python Installation</h3>
<p>
First you want to to install <a href="https://www.anaconda.com/distribution/">Anaconda</a>, and the current version as of writing is Python 3.7.</p>

<p>Once you have downloaded and installed Anaconda, open a <b><a href="https://www.macworld.co.uk/how-to/mac-software/how-use-terminal-on-mac-3608274/">Terminal</a></b> if you're on OSX or <b><a href="https://docs.anaconda.com/anaconda/user-guide/getting-started/">Anaconda Prompt</a></b> if you're on Windows.</p>

<p>You want to create a <b>Virtual Environment</b> for this exercise. The purpose of virtual environment is to create an isolated environment to contain all the packages you will install. Since python is used from machine learning to webscraping to data visualization, sometimes you will encounter an application such as GIS will require python version 2.7 and tensorflow will only work with python version 3.5. So virtual environment is a very convenient way to manage your python installations.</p>

<p>To create a virtual environment in <a href="https://www.anaconda.com/distribution/">Anaconda</a>, in the <b><a href="https://www.macworld.co.uk/how-to/mac-software/how-use-terminal-on-mac-3608274/">Terminal</a></b> or <b><a href="https://docs.anaconda.com/anaconda/user-guide/getting-started/">Anaconda Prompt</a></b>, type:</p>
<pre><code>conda create -n dataviz python=3.6</code></pre>

![test image size](../../../assets/images/pic_anaconda_env.jpg){:height="50%" width="50%"}

<p>When asked to proceed, click <b>Y</b> and press <b>Enter</b>. If you have trouble creating an environment in Anaconda, please refer to this <a href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">page</a> </p>

<p>Now that you have Python running in your system, you want to activate the environment you just created and then start installing all the packages that we will use to complete this workshop. First activate the environment by typing this in the <b>Terminal</b> or <b>Anaconda Prompt</b>.</p>

<pre><code>conda activate dataviz</code></pre>

<p>If you're successful in activating the virtual environment, you should see the name of the enviroment appear in brackets.</p>

![test image size](../../../assets/images/pic_anaconda_activate_env.jpg){:height="50%" width="50%"}

<hr />

<h1>Step 2</h1>
<h3>Jupyter Notebook Installation</h3>
<p>Next we need to install <a href="https://jupyter.org/index.html">Jupyter Notebook</a> by typing the following command in <b>Terminal</b> or <b>Anaconda Prompt</b>, and type <b>Y</b> when asked to Proceed.</p>

<pre><code>conda install jupyter</code></pre>

![test image size](../../../assets/images/pic_jupyter.jpg){:height="50%" width="50%"}

<p>Jupyte Notebook is an Interactive Computing Environment that allows your to get immediate feedback when coding, thereby making programming much more visual and intuitive.</p>

<h3>Installing Other Python Packages</h3>
<p>Next we install <a href="https://plot.ly/python/getting-started/" target="_blank">Plotly</a>, <a href="https://pypi.org/project/numpy/" target="_blank" >Numpy</a>, <a href="https://pypi.org/project/beautifulsoup4/" target="_blank" >Beautifulsoup</a>, and <a href="https://pandas.pydata.org/pandas-docs/stable/install.html" target="_blank" >Pandas</a> by typing the following command in <b>Terminal</b> or <b>Anaconda Prompt</b>.</p>

<pre><code>pip install plotly numpy beautifulsoup4 pandas</code></pre>

<p><a href="https://plot.ly/python/getting-started/" target="_blank" >Plotly</a> is a dynamic graphing web application, <a href="https://pypi.org/project/numpy/" target="_blank" >Numpy</a> is a processor that deal with multidimensional arrays or matrices, <a href="https://pypi.org/project/beautifulsoup4/" target="_blank" >Beautifulsoup</a> is a webscraping module, and <a href="https://pandas.pydata.org/pandas-docs/stable/install.html" target="_blank" >Pandas</a> is a library for data processing.</p>

<hr />

<h1>Step 3</h1>
<h3>Launch Jupyter Notebook</h3>
<p>Next, we first create a folder where all the coding files will reside. In my case I'll create a folder on my desktop call <b>dataviz</b>. You can do that however you want. Once the folder has been created, go back to your <b>Terminal</b> or <b>Anaconda Prompt</b>, then type <b>cd</b> and then the path to your newly created folder. *If you don't like typing the full path of your folder by hand, follow this tip.</p>

<ul class="actions">
	<li><a href="https://searchenterprisedesktop.techtarget.com/photostory/2240216625/Ten-hidden-Windows-command-prompt-tricks/11/Drag-and-drop-a-folder-to-open-command-prompt" target="_blank" class="button">Tip Windows</a></li>
    <li><a href="http://osxdaily.com/2009/11/23/copy-a-files-path-to-the-terminal-by-dragging-and-dropping/" target="_blank" class="button">Tip OSX</a></li>
</ul>

<pre><code>cd /Users/tedngai/Desktop/dataviz</code></pre>

![test image size](../../../assets/images/pic_desktopfolder.jpg){:height="50%" width="50%"}

<p>Once you're in your newly created folder, copy download these 2 data file and place them into your folder, and then you can launch Jupyter Notebook by typing the following. Your web browser should open the web app, and Jupyter should now show your current location. </p>

<ul class="actions">
	<li><a href="../../../assets/files/SalaryScrape.zip" class="button">Download Data File</a></li>
</ul>

<pre><code>jupyter notebook</code></pre>

![test image size](../../../assets/images/pic_jupyternotebook_launch.jpg){:height="50%" width="50%"}

<p>Last but not least, click the <b>New</b> button at the near top right and click on Python 3 to create a new notebook. And congratulations, if you are able to get to this point, you are all set to do some exciting programming. If you have trouble getting things to work thus far, please carefully review the steps and make sure you have your virtual environment activated and you are in a proper folder. If you continue to have problem, please feel free to contact us via Slack or email.</p>

![jupyter new notebook](../../../assets/images/pic_jupyternotebook_new.jpg){:height="50%" width="50%"}

<hr />

<h1>Step 4</h1>
<h3>Webscraping & Dataprocessing</h3>
<p>Webscraping is a very powerful tool for data visualization especially if you're interested in culturo-socio-polico-economic issues. This tool allows you to tap into vast amount of data from sometimes not so data friendly sources. In this example, we will look at salay levels of people who work in the New York Public Education System. By deploying the Freedom of Information Act, many organizations have requested and released data such as salary levels of all public employees across the country. This is an invaluable tool to demand accountability for people holding public offices. However, these dataset do not always come in a format that is ready to be visualized. In our case, we will use the data released by the <a href="https://www.seethroughny.net/" target="_blank" ><b>Empire Center</b></a> looking at salary levels of employees working in the CUNY system.</p>

<p>To start, the data cannot be downloaded with the click of a button. So we'll need to do some detective work and see how we can collect the information we want. Make sure you have <a href="https://www.seethroughny.net/" target="_blank" >seethroughny.net</a> opened. Go to <b>Menu > Payrolls > Schools</b>, then under <b>Filter > Employer / Agency</b>, type in <b>Fashion Institute of Technology</b>. You can click the following button to see this data on their website, the actual data file is provided for you earlier as well.</p>

<ul class="actions">
	<li><a href="https://www.seethroughny.net/payrolls/107209525" target="_blank" class="button">FIT Payroll</a></li>
</ul>

<p>We will cover how to use python to access web pages and webscrape with code at a different exercise. For now, I have already prepared and downloaded part of the html data for you so we can jump into data processing and visualization immediately.</p>

p>Now let's go back to Jupyter Notebook, and in the first line, type in the following, and then <b>Hit SHIFT + ENTER</b> to execute the code.</p>

<pre><code>from bs4 import BeautifulSoup
import pandas as pd
import codecs</code></pre>

![jupyter first](../../../assets/images/pic_jupyter_firstline.jpg){:height="50%" width="50%"}

<p>Python is a very powerful programming language due to the fact that it has a large community of developers writing libraries to handle lower level programming, allowing you to concentrate on the big ideas.</p>

<p>There're many libraries and packages out there that will handle different types of programming issues. For us, the first step is to install the packages as we did earlier using pip install. And these few lines of code is to tell python that these packages are already installed and we need to deploy them into the current system.</p>

<p>Next we need to load the data file. Do that by typing the following and the <b>Hit SHIFT + ENTER</b> again to execute the code.</p>

<pre><code>f = codecs.open("./FIT_salaryscrape.txt", "r")

data = []

soup = BeautifulSoup(f.read())
rows = soup.find_all('tr')
for row in rows[::2]:
    cols = row.find_all('td')
    cols = [ele.text.strip() for ele in cols]
    data.append([ele for ele in cols[1:] if ele])</code></pre>

![jupyter load data](../../../assets/images/pic_jupyter_load_data.jpg){:height="50%" width="50%"}

<p>The first line of code here is to read the text file into the variable <b>f</b>. The second line is to create an <b>Empty Array</b> named data. Think of it as a bucket that will hold the data that will come in, and this is just to prepare for it. Third line is to call on BeautifulSoup to read the text file. BeautifulSoup is made to parse html files, and the text file we just loaded is really just html that has been copied and pasted to contain only the data portion. By using BeautifulSoup we can process the data much quicker without having to write low level code ourselves. At this point, the variable <b>soup</b> should contain the whole text files. Try typing in <b>soup</b> in the next time and execute it, you should see the HTML content.</p>

![jupyter soup](../../../assets/images/pic_jupyter_soup.jpg){:height="50%" width="50%"}

<p>If you're not familiar with HTML, it's basically a big mix of human readable language mixed with machine language, allowing for both human and machine to access the same set of information, therefore creating a convergence. Most of the machine language is contained within this <> bracket call <b>Tags</b>. There're lots of common tags, and the one that we see here is <b>TR</b> and <b>TD</b>. <b>TR</b> represents <b>Table / Row</b>, and <b>TD</b> represents <b>Table / Data cell</b>. Each row of data begins with the tag <b>TR</b> and end with this tag <b>/TR</b>. And as we can see here, there're a bunch of <b>TD</b> tags within the <b>TR</b> tags. So if we look at the python code, BeautifulSoup is used to read the whole HTML text file, and then the function <b>final_all</b> is used to locate all the <b>TR</b> tags and they're collected in a variable all <b>ROWS</b>.</p>

<p>This following bit of code is about applyoing a programming logic to go through each row of data and apply the same procedure, and we therefore end up with a programming friendly dataset. <b>for row in rows</b> is a simple way that python goes that every single item in a big list of things. A list is a variable that contains many items, and we created a list of data that contains each row of data from the file earlier. So this function essentially allow us to go through each row of data one by one.</p>

<p>Now that we're inside the for loop, equivalent to plowing through each row of data, we'll identify all the <b>TD</b> tags and then sort them into another list of items with the <b>find_all</b> function.</p>

<p>The next line uses the <b>text.strip()</b> function to get rid of all the machine language or tags so all that remains is human language. Last but not least, the last line puts each row of data that has been processed into a variable that I called a bucket earlier</p>

<hr />
