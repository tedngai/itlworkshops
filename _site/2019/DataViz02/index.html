<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="apple-mobile-web-app-capable" content="yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title> Data Visualization Part 2 Webscraping and Visualization | pratt itl </title> <meta name="description" content=" Pandas, BeautifulSoup, Plotly "> <meta name="keywords" content="technology, education, art, design, new york, brooklyn, architecture"> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <!-- Social: Facebook / Open Graph --> <meta property="og:type" content="article"> <meta property="article:author" content="ITL"> <meta property="article:section" content=""> <meta property="article:tag" content=""> <meta property="article:published_time" content="2019-02-19 00:00:00 -0500"> <meta property="og:url" content="http://localhost:4000/itlworkshops/2019/DataViz02/"> <meta property="og:title" content=" Data Visualization Part 2 Webscraping and Visualization | pratt itl "> <meta property="og:image" content="http://localhost:4000/itlworkshops"> <meta property="og:description" content=" Pandas, BeautifulSoup, Plotly "> <meta property="og:site_name" content="ITL"> <meta property="og:locale" content="en_US"> <!-- Social: Twitter --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:site" content=""> <meta name="twitter:title" content=" Data Visualization Part 2 Webscraping and Visualization | pratt itl "> <meta name="twitter:description" content=" Pandas, BeautifulSoup, Plotly "> <meta name="twitter:image:src" content="http://localhost:4000/itlworkshops"> <!-- Social: Google+ / Schema.org --> <meta itemprop="name" content=" Data Visualization Part 2 Webscraping and Visualization | pratt itl "> <meta itemprop="description" content=" Pandas, BeautifulSoup, Plotly "> <meta itemprop="image" content="http://localhost:4000/itlworkshops"> <!-- Canonical link tag --> <link rel="canonical" href="http://localhost:4000/itlworkshops/2019/DataViz02/"> <link rel="alternate" type="application/rss+xml" title="pratt itl" href="http://localhost:4000/itlworkshops/feed.xml"> <!-- rel prev and next --> <link rel="stylesheet" href="http://localhost:4000/itlworkshops/assets/css/main.css"> </head> <body> <main class="wrapper"> <header class="site-header"> <nav class="nav"> <div class="container"> <h1 class="logo"><a href="http://localhost:4000/itlworkshops/">pratt <span>itl</span></a></h1> <ul class="navbar"> <li><a href="http://localhost:4000/itlworkshops/about">About me</a></li> <li><a href="http://localhost:4000/itlworkshops/feed.xml" target="_blank">RSS</a></li> </ul> </div> </nav> </header> <article class="post container" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <p class="post-meta"><time datetime="2019-02-19T00:00:00-05:00" itemprop="datePublished">Feb 19, 2019</time></p> <h1 class="post-title" itemprop="name headline">Data Visualization Part 2 Webscraping and Visualization</h1> </header> <div class="post-content" itemprop="articleBody"> <hr /> <h2 id="project-description">Project Description</h2> <p>In this workshop session you will learn to do a scrape data off an html doc, process the data by extracting all the data and eliminating all the html tags, and then do a fairly straight forward visualization. By the end of this session, you will learn to do something like this.</p> <iframe width="100%" height="500" frameborder="0" scrolling="no" src="//plot.ly/~tngai/86.embed"></iframe> <hr /> <h1 id="step-1">Step 1</h1> <h3 id="webscraping--dataprocessing">Webscraping &amp; Dataprocessing</h3> <p>Webscraping is a very powerful tool for data visualization especially if you’re interested in culturo-socio-polico-economic issues. This tool allows you to tap into vast amount of data from sometimes not so data friendly sources. In this example, we will look at salay levels of people who work in the New York Public Education System. By deploying the Freedom of Information Act, some organizations have requested and released data such as salary levels of all public employees across the country. This is an invaluable tool to demand accountability for people holding public offices. However, these dataset do not always come in a format that is easy to visualize. In our case, we will dive into a typical use case scenario and use the data released by the <a href="https://www.seethroughny.net/">Empire Center</a>, and look at salary levels of employees working in the CUNY system.</p> <p>To start, the data cannot be downloaded with the click of a button. The data is not stored in any of the contemporary data formats like xml, json, or even csv. So to get the data, we’ll need to do some detective work and see how we can collect the information we want. First visit this website, <a href="https://www.seethroughny.net/">seethroughny.net</a>. Go to Menu &gt; Payrolls &gt; Schools, then under <strong>Filter &gt; Employer / Agency</strong>, type in <strong>Fashion Institute of Technology</strong>. You can use the button below to directly link to the data, the actual data file is provided for you as well.</p> <p>For direct link:</p> <center><button class="button"> <a href="https://www.seethroughny.net/payrolls/107209525" target="_blank">FIT Payroll</a> </button></center> <p><br /></p> <p>For data files:</p> <center><button class="button"> <a href="../../../assets/files/SalaryScrape.zip">Download Data File</a> </button></center> <p><br /></p> <p>We will cover how to use python to access web pages and webscrape with code at a different exercise. For now, I have already prepared and downloaded part of the html data for you so we can jump into data processing and visualization immediately.</p> <p>If you have not done so already, download, unzip, and move the data file and place them into a new folder, I just created a folder named dataviz on my desktop. Then <strong>Launch Juputer Notebook</strong> by opening a <a href="https://www.macworld.co.uk/how-to/mac-software/how-use-terminal-on-mac-3608274/">Terminal</a> or <a href="https://docs.anaconda.com/anaconda/user-guide/getting-started/">Anaconda Prompt</a>, and type <strong>CD</strong> for “change directory”, and type in the path of the folder where your data file is stored.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cd</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">tedngai</span><span class="o">/</span><span class="n">Desktop</span><span class="o">/</span><span class="n">dataviz</span>  
</code></pre></div></div> <p>Then launch Jupyter Notebook by typing this, it will launch your web browser and should open the web app, and you should see Jupyter and your current folder location.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">jupyter</span> <span class="n">notebook</span>  
</code></pre></div></div> <p>In Jupyter Notebook, click in the space at the first line right next to <strong>In [1]</strong>, and type the following, once it’s done <strong>Hold SHIFT then press ENTER</strong> to execute the code.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">codecs</span>  
</code></pre></div></div> <p><img src="../../assets/images/pic_jupyter_firstline.jpg" alt="jupyter first" height="75%" width="75%" class="center-image" /></p> <p>Python is a very powerful programming language due to the fact that it has a large community of developers writing libraries to handle lower level programming, allowing you to concentrate on the big ideas.</p> <p>There’re many libraries and packages out there that will handle different types of issues. And when ever you install libraries or packages from the opensource community, you will need to <strong>“import”</strong> them into the current system. And that’s what these first 3 lines of code is doing.</p> <p>Next we will need to load the data file. Do that by typing the following and <strong>Hold SHIFT then press ENTER</strong> again to execute the code.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span> <span class="o">=</span> <span class="n">codecs</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="s">"./FIT_salaryscrape.txt"</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span>
</code></pre></div></div> <p>What this line of code is doing is to store the whole text file into a single variable <strong>f</strong>. The <strong>“r”</strong> is to tell python that this is <strong>read-only</strong>. As mentioned before, this text file is basically a copy-paste html code from the webpage. What this means is it contains a lot of html code that needs to be processed. If you are not familiar with HTML code, look here for deep-dive into html code format and structure.</p> <center><button class="button"> <a href="https://www.w3schools.com/html/html_examples.asp">Deep Dive: HTML</a> </button></center> <p><br /></p> <p>What we want to do is to separate html codes from data. Luckily the python library BeautifulSoup is built to do just that. Type in the following code and <strong>Hold SHIFT then press ENTER</strong> to execute.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">rows</span><span class="p">[::</span><span class="mi">2</span><span class="p">]:</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">ele</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">]</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">ele</span> <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">ele</span><span class="p">])</span>  
</code></pre></div></div> <p><img src="../../assets/images/pic_jupyter_load_data.jpg" alt="jupyter load data" height="75%" width="75%" class="center-image" /></p> <p>The first line of code here is to create an <strong>Empty List</strong> named data. Think of it as a bucket that can hold any length of data, and you need to declare it so python knows it before hand. In python, this is one of the very few data types that needs to be declared first. Second line is to call on BeautifulSoup to read the text file and in turn, assign that to the variable <strong>soup</strong>. In the next line, try typing in <strong>soup</strong> in the next line and execute it, you should see the HTML content. By looking at the html code, we can see that the data begins with a row of data that has an ID named resultRow, and the next row has an ID named exapndRow. resultRow has the information we need but expandRow contains mostly junk. This provide crucial information for how the data is structured and that it has a repetitive pattern.</p> <p><img src="../../assets/images/pic_jupyter_soup.jpg" alt="jupyter soup" height="75%" width="75%" class="center-image" /></p> <p>HTML is basically a big mix of human readable language mixed with machine language, allowing for both human and machine to access the same information. Most of the machine language is contained within this &lt;&gt; bracket call <strong>Tags</strong>. There’re lots of common HTML tags, and the one that we see here is <strong>tr</strong> and <strong>td</strong>. <strong>tr</strong> represents <strong>Table / Row</strong>, and <strong>td</strong> represents <strong>Table / Data cell</strong>. Each row of data begins with the tag <strong>tr</strong> and end with the <strong>/tr</strong> tag. All the content contained inside a pair of <strong>tr</strong> tags is considered to be in the same row, like a row of data in an excel spreadsheet. As we can see here, there’re a bunch of <strong>td</strong> tags within the <strong>tr</strong> tags, a bunch of data cells inside a row. So if we look at the python code, BeautifulSoup is used to read the whole HTML text file, and then the function <strong>find_all</strong> is used to locate all the <strong>tr</strong> tags and they’re collected in a variable all <strong>ROWS</strong>. <strong>find_all</strong> creates a <strong>list of lists</strong> where each row of data is stored as an item in the list. For more information on lists, follow the link for a deep dive.</p> <center><button class="button"> <a href="http://openbookproject.net/thinkcs/python/english3e/lists.html">Deep Dive: List of Lists</a> </button></center> <p><br /></p> <p>This following bit of code is about applying a programming logic to go through each row of data, then apply the same procedure repeatedly until some condition is met, and we will end up with a programming friendly dataset. <strong>for row in rows</strong> is a simple way that python goes through every single item in a big list of things and pick through each item. <strong>[::2]</strong> is python’s way to skip every other item, as we need to do here because every other row of html content is non-essential. For a deep-dive into python loop structures, click the following.</p> <center><button class="button"> <a href="https://wiki.python.org/moin/ForLoop">Deep Dive: For Loop</a> </button></center> <p><br /></p> <p>Now that we’re inside the <strong>for loop</strong>, we’ll identify all the <strong>td</strong> tags and then sort them into another list with the <strong>find_all</strong> function again. We then use the <strong>text.strip()</strong> function to get rid of all the machine language or tags so all that remains is human readable language.</p> <p>Last but not least, the last line puts each row of data that has been processed into a variable, something I called a bucket earlier. You can see what the variable data looks like if you just execute the variable data. Type <strong>data</strong> and execute and you should see something like this.</p> <p><img src="../../assets/images/pic_jupyter_data.jpg" alt="jupyter soup" height="75%" width="75%" class="center-image" /></p> <p>As you can see, this data structure is a <strong>list of lists</strong>. It’s a list of every person with Names, School Affiliation, Salary Level, and NYSTRS Description, inside a list of all 377 people. Now it’s time to turn this list of lists into a Pandas dataframe to make visualization much easier. Think of Pandas as a very powerful Excel that can handle lists and tables very well. To do this we need to just give the data a <strong>HEADER</strong>, and then call a function to create a new variable. Execute the following code and then type <strong>df</strong> to show the variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'NAME'</span><span class="p">,</span> <span class="s">'SCHOOL'</span><span class="p">,</span> <span class="s">'SALARY'</span><span class="p">,</span> <span class="s">'TYPE'</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_records</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</code></pre></div></div> <p><img src="../../assets/images/pic_jupyter_df.jpg" alt="jupyter soup" height="75%" width="75%" class="center-image center-image" /></p> <p>Now that you have turned an ordinary <strong>list of lists</strong> into a Pandas <strong>Dataframe</strong>, we will be able to use many of its powerful features to further process the data.</p> <hr /> <h1 id="step-2">Step 2</h1> <h3 id="data-visualizaiton">Data Visualizaiton</h3> <p>We’re now ready to visualize the data. The table we have only has 4 columns of data, 2 of which repeats the same information over and over. So essentially, we only have <strong>names</strong> and <strong>salary</strong> to work with. For something like this, we can do a <a href="https://plot.ly/python/box-plots/">Box Plot</a> that allow us to look at a 1-Dimensional data in an interesting way. For more graph types you can do with Plot.ly, click the following link.</p> <center><button class="button"> <a href="https://plot.ly/python/">Deep Dive: Plot.ly Graphs</a> </button></center> <p><br /></p> <p>For this next part we’ll need to bring in another python package. Plotly is a dynamic graphing package that lets you interact with data live. We will look at the basics of how to use it to graph what we have. So first import the packages by typing in the following.</p> <p>```python import plotly.plotly as py import plotly.graph_objs as go from plotly.offline import download_plotlyjs, init_notebook_mode, iplot</p> <p>init_notebook_mode(connected = True)</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The first 3 lines of code is just to import the Plotly graphing packages. The 4th one is to allow plotly to plot directly inside Jupyter. Once you have executed the code, you can go ahead and input the following code.

```python  
trace0 = go.Box(
        name = "FIT",
        y = df['SALARY'])

layout = go.Layout(
        title = "FIT Faculty Salary")

data = [trace0]
iplot({"data":data,
       "layout":layout})  
</code></pre></div></div> <p>If everything is running correctly, you should see a graph like this one. This is a 1 dimensional graph that gives you a bit of statistical calculation. It tells you what the median value is, what the lower and upper fence is, and what numbers are falling outside of the norm. How going back to the code, <strong>trace0</strong> is defined to use Box graph and you assign the Y axis to only the <strong>SALARY</strong> column of the dataframe. For layout, we’re naming the graph FIT Faculty Salary. Data is needed to put trace0 in a square bracket. This step is necessary because if we want to plot more than 1 column of data, we can put multiple values here. Lastly, the iplot command sends the plot to jupyter.</p> <iframe width="400" height="500" frameborder="0" scrolling="no" src="//plot.ly/~tngai/78.embed"></iframe> <p>You can download the jupyter file here and review the all the inputs here.</p> <ul class="actions"> <li><a href="../../assets/files/FIT_bs4.ipynb" class="button">Download Data File</a></li> </ul> <h3 id="alternate-visualizaiton">Alternate Visualizaiton</h3> <p>Although this visualization is very straightforward, you can improve it by showing the points data to understand the distribution a little better. To do this you just need to add 3 lines of code: <code class="highlighter-rouge">boxpoints='all'</code> to show all the points, <code class="highlighter-rouge">jitter</code> is to “spread” the points to a certain width, and <code class="highlighter-rouge">pointpos</code> is to move the position so it doesn’t overlap with the box itself.</p> <p><code class="highlighter-rouge">python boxpoints='all', jitter=0.2, pointpos=-1.5 </code></p> <p>All together it would look something like this.</p> <p>```python trace0 = go.Box( name = “FIT”, y = df[‘SALARY’], boxpoints=’all’, jitter=0.2, pointpos=-1.5)</p> <p>layout = go.Layout( title = “FIT Faculty Salary”)</p> <p>data = [trace0] iplot({“data”:data, “layout”:layout}) ```</p> <iframe width="50%" height="500" frameborder="0" scrolling="no" src="//plot.ly/~tngai/82.embed"></iframe> <h1 id="step-3">Step 3</h1> <p>###Data Visualizaiton Challenge Let’s try to apply everything we’ve learn so far and apply it to a more challenging dataset. For this exercise, you will have to learn a few more Pandas commands on data processing. We will use the <strong>CUNY_salaryscrape.txt</strong> file that was downloaded earlier, here’s the link again.</p> <ul class="actions"> <li><a href="../../../assets/files/SalaryScrape.zip" class="button">Download Data File</a></li> </ul> <p>Now before we begin this final challenge, let’s take a look at the file and try to understand what kind of strategy we need to unpack this. First, the text file itself is almost 50Mb, for a text file this is pretty big, which means we have to be a careful about memory management. And upon opening the file, you’ll find that there’re over 12 million lines of text inside. Although not all the lines are useful data, we’ll need to devise a way to efficiently extract only the useful information out.</p> <p>Now let’s open up the file and look at the first 2 rows of data under the <strong>tr</strong> tag and try to see what we’re dealing with. The file opens with an html tag <code class="highlighter-rouge">&lt;tbody&gt;</code> followed by 1 <code class="highlighter-rouge">&lt;tr&gt;</code> tag and a bunch of <code class="highlighter-rouge">&lt;td&gt;</code> tags. This part of the file is exactly the same as the previous exercie. The <code class="highlighter-rouge">&lt;tr&gt;</code> tags have 2 different <code class="highlighter-rouge">id</code> types: 1 is the <strong><em>resultRow</em></strong> and the other is the <strong><em>expandRow</em></strong>, with <strong><em>resultRow</em></strong> showing the basic information and <strong><em>expandRow</em></strong> showing supplemental information. Unlike the previous example, we can’t just simply discard the expandRow, this means we will have to accomodate that with our code.</p> <p>Also, the first row of data is separated into columns with the <code class="highlighter-rouge">&lt;td&gt;</code> tags whereas the second row is tag is separated <code class="highlighter-rouge">&lt;div&gt;</code> tags. So the 2 rows of data will have to be parsed differently.</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;tbody&gt;&lt;tr id="resultRow88275159" onclick="stnyResultTable.toggleRow(88275159); return false;"&gt;
    &lt;td&gt;&lt;a href="#"&gt;&lt;i class="glyphicon glyphicon-minus"&gt;&lt;/i&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;El Mohandes, Ayman&lt;/td&gt;
    &lt;td&gt;CUNY&lt;/td&gt;
    &lt;td&gt;$544,685&lt;/td&gt;
    &lt;td class="visible-sm visible-md visible-lg"&gt;School of Public Health Lag&lt;/td&gt;
        &lt;/tr&gt;
	&lt;tr id="expandRow88275159" style=""&gt;
    &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;td colspan="5"&gt;
        &lt;div class="row visible-xs-block"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;SubAgency/Type&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;School of Public Health Lag&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;Dean School Of Public Health&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;Rate of Pay&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;$443,000&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;Pay Year&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;2018&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;Pay Basis&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;Annual&lt;/div&gt;
        &lt;/div&gt;
        &lt;div class="row"&gt;
            &lt;div class="col-xs-4"&gt;&lt;strong&gt;Branch/Major Category&lt;/strong&gt;&lt;/div&gt;
            &lt;div class="col-xs-6"&gt;State - Executive&lt;/div&gt;
        &lt;/div&gt;
            &lt;/td&gt;
</code></pre></div></div> <p>Ok so let’s just dive right into this. First, again, import all the packages we need by executing the following code.</p> <p>```python from bs4 import BeautifulSoup import pandas as pd from collections import defaultdict import plotly.plotly as py import plotly.graph_objs as go from plotly.offline import download_plotlyjs, init_notebook_mode, iplot import codecs</p> <p>init_notebook_mode(connected = True) ```</p> <p>Next, read the data file and use BeautifulSoup to sort all the rows of data into a list of lists.</p> <p><code class="highlighter-rouge">python f = codecs.open("./CUNY_salaryscrape.txt", "r") soup = BeautifulSoup(f.read()) rows = soup.find_all('tr') </code></p> <p>Same as before, the following code is to go through each row of data and extract all the <code class="highlighter-rouge">&lt;td&gt;</code> tags and put them in the right place. However, as mentioned before, the data is structured differently this time, so all the extra code here is to deal with the alternating rows and the different data tags used.</p> <p>Not to get too much into the technical detail, but the idea is to use 2 buckets, 1 to hold data for very 2 rows of data, which will then be dumped into the other bucket, and then empty itself out. So this is a way to get around the quirkiness data structure that was provided.</p> <p>```python data = [] temp = [] i = 0</p> <p>def flatten(temp): return [item for sublist in temp for item in sublist]</p> <p>for row in rows: cols = row.find_all(‘td’) cols = [ele.text.strip() for ele in cols] temp.append(cols[1:]) i += 1 if i%2 == 0: templist= temp[1][0].split(‘ ‘) temp[1]=templist flattemp = flatten(temp) data.append([ele for ele in flattemp if ele]) temp = [] ```</p> <p>Now that we have a list of lists with all the useful data in it, it’s time to turn them into a Pandas dataframe for further processing.</p> <p>```python labels = [‘NAME’, ‘SCHOOL’, ‘SALARY’, ‘DEPARTMENT’, ‘SUBAGENCY TYPE’,’SUBAGENCY’,’TITLE TYPE’,’TITLE’,’RATEOFPAY TYPE’, ‘RATE OF PAY’,’PAYYEAR TYPE’, ‘PAY YEAR’, ‘PAYBASIS TYPE’, ‘PAY BASIS’,’BRANCH TYPE’, ‘BRANCH’]</p> <p>df = pd.DataFrame.from_records(data, columns=labels) ```</p> <p>Since the 2nd row of data contains a lot of “junk” data we will need to eliminate some of the columns of data that was just created. We’re doing it this way instead of parsing it out during the input phase because it’s a lot easier to remove columns with Pandas than to use logic to filter out unwanted data.</p> <p>```python df = df.drop([‘SUBAGENCY TYPE’,’TITLE TYPE’, ‘RATEOFPAY TYPE’,’SUBAGENCY’, ‘PAYYEAR TYPE’, ‘PAY YEAR’,’PAYBASIS TYPE’, ‘BRANCH TYPE’,’BRANCH’],axis=1)</p> <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
If everything is going smoothly up to this point, you should see something like this when you type in `df`

![](../../../assets/images/pic_CC_df.jpg){:height="75%" width="75%"}

Now that we have the whole dataset with 34,000 rows of data, we can see we have actually more than 1 dimension to work with. So for this exercise, let's filter the amount of data down. If you see the **DEPARTMENT** column, this dataset includes employees in the whole **CUNY** system. So let's starts with singling out a specific college and concentrate on that. In our case, we'll only look at people who work at the **City College**. To do this we need to figure out how many different **DEPARTMENTS** there are. You can do this in many different ways but a powerful and pythonic way is to write a function. This following is an example to list all the duplicates and in which record the duplicate appears. For now, we're not going to go into the details so we'll just assume this is a button in a computer software you can press and it'll get you what you need. 

```python  def list_duplicates(seq):
    tally = defaultdict(list)
    for i, item in enumerate(seq):
        tally[item].append(i)
    return((key,locs) for key, locs in tally.items() if len(locs)&gt;0)  ```

Now that the function to find duplicate is in place, we can call the function with the following code. Essentially we're setting an empty bucket called departments, and all the variations will be collected into that variable. And if you execute the code successfully, you should see something like the following.

```python  departments = []
for dup in sorted(list_duplicates(df['DEPARTMENT'])):
    departments.append(dup[0])  ```

![](../../../assets/images/pic_jupyter_CC_departments.jpg){:height="75%" width="75%"}

As you can see, **City College** is named in different ways like **City College**, **City College Adjunct**, **City College EH**, **City College Hourly**...etc. The code we'll use to extract that will need to be able to catch all the variations. Luckily Pandas lets us do this very easily. In this case, a new variable named **df_cc** is used to catch all the data that contains the word **City College** in it.

```python  df_cc = df[df['DEPARTMENT'].str.contains('City College')]
</code></pre></div></div> <p>Now that we have singled out only employees working at the City College, we want to look at the different positions people take and compare their salary levels. And let’s assume this time that we’re only intereste in people who are in teaching positions not administrative. Execute the following code and we’ll have a new variable named <strong>df_cc_prof</strong> with data that only has <strong>Prof</strong> and <strong>Lect</strong> in the data.</p> <p>```python titles = [] for dup in sorted(list_duplicates(df_cc_prof[‘TITLE’])): titles.append(dup[0])</p> <p>searchfor = [‘Prof’, ‘Lect’] df_cc_prof = df_cc[df_cc[‘TITLE’].str.contains(‘|’.join(searchfor))] ```</p> <p>Lastly, we use Plotly again to visualize the data.</p> <p>```python y0 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Professor’][‘SALARY’] y1 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Assoc Professor’][‘SALARY’] y2 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Asst Professor’][‘SALARY’] y3 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Adjunct Assoc Profess’][‘SALARY’] y4 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Adjunct Asst Professo’][‘SALARY’] y5 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Adjunct Professor’][‘SALARY’] y6 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Visiting Prof’][‘SALARY’] y7 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Visiting Assoc Profes’][‘SALARY’] y8 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Visiting Asst Profess’][‘SALARY’] y9 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Lecturer’][‘SALARY’] y10 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Clinical Professor’][‘SALARY’] y11 = df_cc_prof[df_cc_prof[‘TITLE’] == ‘Research Professor’][‘SALARY’]</p> <p>trace0 = go.Box( name = “Professor”, y = y0, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace1 = go.Box( name = “Assoc Professor”, y = y1, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace2 = go.Box( name = “Asst Professor”, y = y2, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace3 = go.Box( name = “Adjunct Assoc Profess”, y = y3, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace4 = go.Box( name = “Adjunct Asst Professo”, y = y4, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace5 = go.Box( name = “Adjunct Professor”, y = y5, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace6 = go.Box( name = “Visiting Prof”, y = y6, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace7 = go.Box( name = “Visiting Assoc Profes”, y = y7, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace8 = go.Box( name = “Visiting Asst Profess”, y = y8, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace9 = go.Box( name = “Lecturer”, y = y9, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace10 = go.Box( name = “Clinical Professor”, y = y10, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>trace11 = go.Box( name = “Research Professor”, y = y11, boxpoints=’all’, jitter=0.3, pointpos=-1.8)</p> <p>layout = go.Layout( title = “City College Faculty Salary”)</p> <p>data = [trace0, trace1, trace2, trace3, trace4, trace5, trace6, trace7, trace8, trace9, trace10, trace11] iplot({“data”:data, “layout”:layout }) ```</p> <iframe width="100%" height="500" frameborder="0" scrolling="no" src="//plot.ly/~tngai/86.embed"></iframe> <hr /> <h1 id="summary">Summary</h1> <h3 id="what-you-have-learned">What You have Learned</h3> <ul> <li>How to create and assign value to a variable</li> <li>How to create and assign values a list</li> <li>How to create and assign values a list of lists</li> <li>How to bring data into Python as text or csv files</li> <li>How to create and use a counter</li> <li>How to write a basic function</li> <li>How to call a basic function</li> <li>Basic loop structure - how to use for-loops</li> <li>How to import packages in Python</li> <li>How to use basic functions of packages like Pandas, Plotly, BeautifulSoup</li> <li>How to create interactive plots with Plotly.</li> </ul> </div> </article> <footer class="site-footer"> <div class="container"> <small class="block">&copy; 2019 ITL &middot; &lt;/&gt; Powered by <a href="https://jekyllrb.com/">Jekyll</a> and <a href="https://github.com/heiswayi/thinkspace">Thinkspace theme</a></small> </div> </footer> </main> <script type="text/javascript"> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-XXXXX-XX']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> </body> </html>
