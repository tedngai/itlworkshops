<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="apple-mobile-web-app-capable" content="yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title> Natural Language Processing Part 1 Data Cleanup &amp; Exploratory Data Analysis | pratt itl </title> <meta name="description" content=" Python, Pandas, BeautifulSoup, Regular Expression "> <meta name="keywords" content="technology, education, art, design, new york, brooklyn, architecture"> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <!-- Social: Facebook / Open Graph --> <meta property="og:type" content="article"> <meta property="article:author" content="ITL"> <meta property="article:section" content=""> <meta property="article:tag" content=""> <meta property="article:published_time" content="2019-03-23 00:00:00 -0400"> <meta property="og:url" content="http://localhost:4000/itlworkshops/2019/NLP_part1/"> <meta property="og:title" content=" Natural Language Processing Part 1 Data Cleanup &amp; Exploratory Data Analysis | pratt itl "> <meta property="og:image" content="http://localhost:4000/itlworkshops"> <meta property="og:description" content=" Python, Pandas, BeautifulSoup, Regular Expression "> <meta property="og:site_name" content="ITL"> <meta property="og:locale" content="en_US"> <!-- Social: Twitter --> <meta name="twitter:card" content="summary_large_image"> <meta name="twitter:site" content=""> <meta name="twitter:title" content=" Natural Language Processing Part 1 Data Cleanup &amp; Exploratory Data Analysis | pratt itl "> <meta name="twitter:description" content=" Python, Pandas, BeautifulSoup, Regular Expression "> <meta name="twitter:image:src" content="http://localhost:4000/itlworkshops"> <!-- Social: Google+ / Schema.org --> <meta itemprop="name" content=" Natural Language Processing Part 1 Data Cleanup &amp; Exploratory Data Analysis | pratt itl "> <meta itemprop="description" content=" Python, Pandas, BeautifulSoup, Regular Expression "> <meta itemprop="image" content="http://localhost:4000/itlworkshops"> <!-- Canonical link tag --> <link rel="canonical" href="http://localhost:4000/itlworkshops/2019/NLP_part1/"> <link rel="alternate" type="application/rss+xml" title="pratt itl" href="http://localhost:4000/itlworkshops/feed.xml"> <!-- rel prev and next --> <link rel="stylesheet" href="http://localhost:4000/itlworkshops/assets/css/main.css"> </head> <body> <main class="wrapper"> <header class="site-header"> <nav class="nav"> <div class="container"> <h1 class="logo"><a href="http://localhost:4000/itlworkshops/">pratt <span>itl</span></a></h1> <ul class="navbar"> <li><a href="http://localhost:4000/itlworkshops/about">About me</a></li> <li><a href="http://localhost:4000/itlworkshops/feed.xml" target="_blank">RSS</a></li> </ul> </div> </nav> </header> <article class="post container" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <p class="post-meta"><time datetime="2019-03-23T00:00:00-04:00" itemprop="datePublished">Mar 23, 2019</time></p> <h1 class="post-title" itemprop="name headline">Natural Language Processing Part 1 Data Cleanup & Exploratory Data Analysis</h1> </header> <div class="post-content" itemprop="articleBody"> <p><img src="../../assets/images/NLP/AndrewYang.jpg" alt="AndrewYang" /></p> <h2 id="project-description">Project Description</h2> <p>This is part 1 of the Natural Language Processing module. The process described here largely follows the structure of Alice Zhao’s (A Dash of Data) <a href="https://www.youtube.com/watch?v=xvqsFTUsOmc" target="_blank">Presentation on NLP at PyOhio 2018</a>. This first part will mainly focused on webscraping and cleaning up data for Natural Language Processing. We will also deviate from Alice’s presentation and scrape our own dataset from <a href="https://jrescribe.com/" target="blank">Joe Rogan’s podcast transcript</a>. The transcript from Rogan’s Podcast is preferred because of the length and the varieties of his interviews, we get some very interesting results.</p> <p>The main goal for this module is to introduce the idea of vectorization of data, an essential step in regression and classification, which is the precursor to machine learning. When face with data types such as word or sound, we need to find ways to represent the data with numbers, and the numerical representation would be called <strong>Vectors</strong> for 1-dimensional values, <strong>Matrices</strong> for 2-dimensional values, and <strong>Tensors</strong> for higher dimensions. NLP relies on a package in <a href="https://scikit-learn.org/stable/" target="_blank">SCIKIT-Learn</a>, a very popular machine learning library in python, to convert words to vectors, which then enable us to do higher level analysis.</p> <p>Before you begin, you must have completed the installation and visualiation modules so you have working knowledge of anaconda and regular expression.</p> <hr /> <h1 id="step-1">Step 1</h1> <h2 id="download-data">Download Data</h2> <p>For this exercise we will be using <strong>BeautifulSoup</strong> to scrape data off <a href="https://jrescribe.com/" target="blank">Joe Rogan’s podcast transcript</a> site, and I have chosen 16 interviews based on the range of ideas being discussed. To get that started, import the following packages.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">requests</span><span class="p">,</span> <span class="n">pickle</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
</code></pre></div></div> <p>Next we will define a function to launch BeautifulSoup and scrape the data, a list of urls to the interview transcripts, a list of speakers, and a list of the full name of the speakers.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">url_to_transcript</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">text</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"content"</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'p'</span><span class="p">)]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'https://jrescribe.com/transcripts/p1255.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1245.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1233.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1213.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1227.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1216.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1236.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1234.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1198.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1184.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1169.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1121.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1260.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1248.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1241.html'</span><span class="p">,</span>
        <span class="s">'https://jrescribe.com/transcripts/p1240.html'</span><span class="p">,</span>
          <span class="p">]</span>

<span class="n">speakers</span> <span class="o">=</span> <span class="p">[</span><span class="s">'jones'</span><span class="p">,</span> <span class="s">'yang'</span><span class="p">,</span><span class="s">'cox'</span><span class="p">,</span><span class="s">'weil'</span><span class="p">,</span><span class="s">'tyson'</span><span class="p">,</span><span class="s">'penrose'</span><span class="p">,</span><span class="s">'dorsey'</span><span class="p">,</span><span class="s">'sinclair'</span><span class="p">,</span>
            <span class="s">'brown'</span><span class="p">,</span><span class="s">'barr'</span><span class="p">,</span><span class="s">'musk'</span><span class="p">,</span><span class="s">'pollen'</span><span class="p">,</span><span class="s">'lewis'</span><span class="p">,</span><span class="s">'ottman'</span><span class="p">,</span><span class="s">'harris'</span><span class="p">,</span><span class="s">'galante'</span><span class="p">,</span>
           <span class="p">]</span>

<span class="n">full_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Alex Jones'</span><span class="p">,</span> <span class="s">'Andrew Yang'</span><span class="p">,</span> <span class="s">'Brian Cox'</span><span class="p">,</span> <span class="s">'Andrew Weil'</span><span class="p">,</span> <span class="s">'Mike Tyson'</span><span class="p">,</span> <span class="s">'Roger Penrose'</span><span class="p">,</span>
              <span class="s">'Jack Dorsey'</span><span class="p">,</span> <span class="s">'David Sinclair'</span><span class="p">,</span><span class="s">'Darren Brown'</span><span class="p">,</span><span class="s">'Rosanne Barr'</span><span class="p">,</span><span class="s">'Elon Musk'</span><span class="p">,</span><span class="s">'Michael Pollen'</span><span class="p">,</span>
              <span class="s">'Lennox Lewis'</span><span class="p">,</span> <span class="s">'Bill Ottman'</span><span class="p">,</span><span class="s">'Sam Harris'</span><span class="p">,</span><span class="s">'Forrest Galante'</span><span class="p">]</span>
</code></pre></div></div> <p><code class="highlighter-rouge">text = [p.text for p in soup.find(class_="content").find_all('p')]</code> This line in the function is the key that pulls out the text the whole interview. It finds the div tag <strong>class=”content”</strong> which contains the transcript, and strips out all the html code. Next we call the function to store all the text into the variable <strong>transcript</strong>. This is a very Pythonic syntax which is a short form for writing a loop. In the long form, it is equivalent to:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"content"</span><span class="p">)</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'p'</span><span class="p">):</span>
  <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></div> <p>And we can even break this down further into simpler components, which is to say, first find the div class named content, then find all the paragraph tags in there, then put all those paragraphs into the text variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text</span><span class="o">=</span><span class="p">[]</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">class_</span><span class="o">=</span><span class="s">"content"</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">'p'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">b</span><span class="p">:</span>
  <span class="n">text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</code></pre></div></div> <p>Now let’s get back on track, call the function to process all the urls and get all the text into the transcript variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transcript</span> <span class="o">=</span> <span class="p">[</span><span class="n">url_to_transcript</span><span class="p">(</span><span class="n">u</span><span class="p">)</span> <span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">]</span>
</code></pre></div></div> <p>Again, notice the short form. This could have been written as-</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">transcript</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">u</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
  <span class="n">transcript</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">url_to_transcript</span><span class="p">(</span><span class="n">u</span><span class="p">))</span>
</code></pre></div></div> <p>Once its done scraping, now we <strong>“pickle”</strong> all the transcripts into our local storage. <strong>Pickling</strong> here means saving what ever is in the variable into a file, which can then be called later. The following code shows how to <strong>pickle</strong> the transcripts and using the <strong>speakers</strong> list to save each transcrption with their names. And later we retrieve the <strong>pickled</strong> data back and create a <strong>dictionary</strong> to correlate the <strong>speakers</strong> to the <strong>transcripts</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">speakers</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'transcripts/'</span> <span class="o">+</span> <span class="n">s</span> <span class="o">+</span> <span class="s">".txt"</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">transcript</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">file</span><span class="p">)</span>
        
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">speakers</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'transcripts/'</span> <span class="o">+</span> <span class="n">s</span> <span class="o">+</span> <span class="s">'.txt'</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">data</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
</code></pre></div></div> <p>Typing the following and see that you now have a dictionary with <strong>key:speakers</strong> and <strong>value:transcript</strong> structure.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div> <p>However, you can see that the <strong>transcripts</strong> is a <strong>list</strong> of texts due to the function call <strong>find_all(‘p’)</strong>, all html paragraphs with a <strong>&lt;p&gt;</strong> tag were imported as a separate list item. <strong>[:2]</strong> shows the beginning to the 3rd item in the list, and <strong>[1:5]</strong> will show the second to 6th item in the list.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="s">'weil'</span><span class="p">][:</span><span class="mi">2</span><span class="p">]</span>
</code></pre></div></div> <p>We need to change the dictionary from <strong>value:list</strong> to <strong>value:string</strong>. We can do that with a function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">combine_text</span><span class="p">(</span><span class="n">list_of_text</span><span class="p">):</span>
    <span class="n">combined_text</span> <span class="o">=</span> <span class="s">' '</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">list_of_text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">combined_text</span>
  
<span class="n">data_combined</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="p">[</span><span class="n">combine_text</span><span class="p">(</span><span class="n">value</span><span class="p">)]</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
</code></pre></div></div> <p>Next we can put everything into a Pandas DataFrame.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'max_colwidth'</span><span class="p">,</span> <span class="mi">150</span><span class="p">)</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data_combined</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="n">data_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'transcript'</span><span class="p">]</span>
<span class="n">data_df</span>
</code></pre></div></div> <p>Now you get a small glimpse of what the transcript look like, we now need to clean up all the text. By that, it means we need to get rid all the things that are irrelevant to our analysis such as punctuations, capitalization, numerical values, symbols…etc. The most effective method to do this is by using <strong>regular expressions</strong>. We have already done a little bit <strong>regex</strong> in the previous exercise so we will not discuss the overall concept, and we will just concentrate on the specific syntax used here and explain what it achieves. Type in <code class="highlighter-rouge">data_df.transcript.loc['weil']</code> to display the transcript for Dr. Andrew Weil and see what kind of clean up you should expect.</p> <blockquote> <p>‘Dr. Andrew Weil is a physician, author, spokesperson, and broadly described “guru” of the alternative medical brands: holistic health and integrative medicine.\xa0https://matcha.com/pages/joerogan Help improve this transcript! Hello friends how's everybody doing out there I hope you groovy I hope you're groovy this holiday season hits this season it's interesting how we need Seasons we need two reasons for stuff to celebrate when we give you a reason imma give me an interesting one now through December 25th 23andMe DNA kits are on sale 23andMe if you don't know what it is it's a DNA test kit they send you a package with a tube in it you spit in the tube provided in your 23andMe kit you register your sample to your personal 23andMe account and in a few weeks you receive your personalized online reports 23andMe it's based on the 23 pairs of chromosomes that help make up your DNA and with this test they can tell you all sorts of stuff about your jeans in your ancestors and they cannot explain about why you have certain things going on with your body like how about mosquito bite frequency is that one actually you some people find that they get more mosquito bites and other people and what makes some people more attractive to mosquitoes and others will genetics may be partly to blame about cilantro taste aversion like the some people really fucking hate cilantro they think it tastes like soap if you have a genetic marker associated with this aversion that might be you weird right about muscle composition does a genetic muscle composition it's common in Elite power athletes the studies have found that almost all Elite power athletes have a very specific genetic variant in a gene related to muscle composition 23andMe muscle composition important about that they can they can help you explore the link between your DNA in your muscle composition also find out you know what what do you got in there when you got you got African you got European like yes Asian in their butts really essentially and just really interesting I did it I found out I'm 1.6% African mostly Italian which is what I thought and the rest is either Irish or English you know interesting stuff folks and super easy to do and now through December 25th you can get 30% off any 23andMe kit you order your DNA kit at 23andme.com Rogan that's the number to 3 a.m. D and me.com road again it's 23andme.com Rogan December 21st 30% off any 23andMe kit we're also brought you buy stamps. now if you send things to the post office on a regular basis and you don't know about urine for a tree to stamps.com is the easiest way to access all of the amazing Services of the US Post Office and now is the holidays the fucking holidays man those lines are brutal you got to send things you want to you want to wait that long you don't have to stamps.com it's saves you so much time this is how it works really easy you can buy and print official US postage for any letter any package any class of mail using your own computer and printer and then you let the mail carrier pick it up or you drop it off in the mailbox and you're done no trips to the post office required it could not be easier it's a wonderful thing and you don't have to lie world's expensive postage meters stamps.com print postage any day any time whatever you want not only save you time to save you money is stamps.com helps you print the right amount of postage every time never overpay again and with stamps.com you get discounts on postage you can't even get at the post office just think about all the time and the money that you'll save it's a wonderful gift as well folks and right now you too can enjoy the stamps.com service with a special offer that includes a 4 week trial class postage and a digital scale without long-term commitments go to stamps.com click on the microphone at the top of the home ‘</p> </blockquote> <p>As you can see the text is relatively clean, so we will just focus one the obvious issues.</p> <p>The <strong>regex</strong> routine is written as a function call <strong>clean_text_round1</strong>. What kind of cleanup you will need really depends on where you scraped your text from, and in our case, there are quite a bit of html The first line removes capitalization. The second line removes anything in square brackets, <code class="highlighter-rouge">\</code> is an escape character so this -<code class="highlighter-rouge">\[ \]</code> means to treat the square brackets is something to search for and not something as part of the programming language. <code class="highlighter-rouge">.</code> is any character including any alphanumeric character, <code class="highlighter-rouge">*</code> is to match the expression to the left 0 or more times, <code class="highlighter-rouge">?</code> is to match the expression to the left 0 or 1 times. In all <code class="highlighter-rouge">\[.*?\]</code> means match anything that’s within square brackets and replace it with <code class="highlighter-rouge">''</code> which means empty string. The third line removes punctuations. The fourth line removes any words containing numbers. <code class="highlighter-rouge">\d</code> is any digits sandwiched between this - <code class="highlighter-rouge">\w</code> - any alphanumeric characters <code class="highlighter-rouge">*</code> repeated 0 or more times.’</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span><span class="p">,</span> <span class="n">string</span>

<span class="k">def</span> <span class="nf">clean_text_round1</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'</span><span class="err">\</span><span class="s">[.*?</span><span class="err">\</span><span class="s">]'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'[</span><span class="si">%</span><span class="s">s]'</span> <span class="o">%</span> <span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">),</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'</span><span class="err">\</span><span class="s">w*</span><span class="err">\</span><span class="s">d</span><span class="err">\</span><span class="s">w*'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">'[^A-Za-z0-9 ]+'</span><span class="p">,</span> <span class="s">''</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="n">round1</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">clean_text_round1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">data_clean</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_df</span><span class="o">.</span><span class="n">transcript</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">round1</span><span class="p">))</span>
</code></pre></div></div> <p>Once the first round of cleaning is done, type <code class="highlighter-rouge">data_clean.transcript.loc['weil']</code> to see the “clean” text and see what else needs to be done. But in our case here, it looks like we can already move forward to the next step.</p> <blockquote> <p>‘dr andrew weil is a physician author spokesperson and broadly described guru of the alternative medical brands holistic health and integrative medicinehttpsmatchacompagesjoerogan help improve this transcript hello friends hows everybody doing out there i hope you groovy i hope youre groovy this holiday season hits this season its interesting how we need seasons we need two reasons for stuff to celebrate when we give you a reason imma give me an interesting one now through december dna kits are on sale if you dont know what it is its a dna test kit they send you a package with a tube in it you spit in the tube provided in your kit you register your sample to your personal account and in a few weeks you receive your personalized online reports its based on the pairs of chromosomes that help make up your dna and with this test they can tell you all sorts of stuff about your jeans in your ancestors and they cannot explain about why you have certain things going on with your body like how about mosquito bite frequency is that one actually you some people find that they get more mosquito bites and other people and what makes some people more attractive to mosquitoes and others will genetics may be partly to blame about cilantro taste aversion like the some people really fucking hate cilantro they think it tastes like soap if you have a genetic marker associated with this aversion that might be you weird right about muscle composition does a genetic muscle composition its common in elite power athletes the studies have found that almost all elite power athletes have a very specific genetic variant in a gene related to muscle composition muscle composition important about that they can they can help you explore the link between your dna in your muscle composition also find out you know what what do you got in there when you got you got african you got european like yes asian in their butts really essentially and just really interesting i did it i found out im african mostly italian which is what i thought and the rest is either irish or english you know interesting stuff folks and super easy to do and now through december you can get off any kit you order your dna kit at rogan thats the number to am d and mecom road again its rogan december off any kit were also brought you buy stamps now if you send things to the post office’</p> </blockquote> <p>Before we do that, let’s pickle the corpus.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_df</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s">'corpus.pkl'</span><span class="p">)</span>
</code></pre></div></div> <p>Now the important step is to <strong>vectorize</strong> the text.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span> <span class="o">=</span> <span class="s">'english'</span><span class="p">)</span>
<span class="n">data_cv</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_clean</span><span class="o">.</span><span class="n">transcript</span><span class="p">)</span>
<span class="n">data_dtm</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_cv</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">data_dtm</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">data_clean</span><span class="o">.</span><span class="n">index</span>
<span class="n">data_dtm</span>
</code></pre></div></div> <p>Last but not least, pickle all the data generated thus far.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_dtm</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s">'dtm.pkl'</span><span class="p">)</span>
<span class="n">data_clean</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s">'data_clean.pkl'</span><span class="p">)</span>
<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="nb">open</span><span class="p">(</span><span class="s">'cv.pkl'</span><span class="p">,</span> <span class="s">'wb'</span><span class="p">))</span>
</code></pre></div></div> <hr /> <h1 id="step-2">Step 2</h1> <h2 id="exploratory-data-analysis">Exploratory Data Analysis</h2> <p>EDA is an important step in data science. This is when you are trying different ways to see how to get some useful information out of the dataset. So lets start by importing pandas and loading the pickled data back.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="s">'dtm.pkl'</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div> <p>First thing to try is to see how many times each speaker say a certain word. Since the whole transcript is vectorized, this is quite easy to do with a <strong>sort</strong> function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">top_dict</span><span class="o">=</span><span class="p">{}</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">top</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">top_dict</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">top</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">top</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
    
<span class="n">top_dict</span>
</code></pre></div></div> <blockquote> <p>{‘jones’: [(‘like’, 511), (‘people’, 309), (‘know’, 271), (‘dont’, 257), (‘just’, 247), (‘im’, 237), (‘thats’, 227), (‘going’, 199), (‘think’, 175), (‘got’, 170), (‘want’, 145), (‘youre’, 144), (‘said’, 123), (‘theres’, 122), (‘theyre’, 120), (‘things’, 113), (‘right’, 108), (‘say’, 106), (‘saying’, 93), (‘really’, 92), (‘believe’, 86), (‘years’, 81), (‘thing’, 80), (‘hes’, 78), (‘did’, 77), (‘real’, 76), (‘cuz’, 73), (‘yeah’, 70), (‘time’, 68), (‘didnt’, 68), (‘way’, 66), (‘big’, 66), (‘good’, 63), (‘trying’, 63), (‘okay’, 62), (‘stuff’, 59), (‘talk’, 58), (‘guy’, 58), (‘lot’, 58), (‘doing’, 56), (‘mean’, 56), (‘ive’, 56), (‘look’, 55), (‘tell’, 54), (‘ago’, 52), (‘whats’, 52), (‘god’, 50), (‘bad’, 50), (‘make’, 49), (‘happened’, 48), (‘point’, 44), (‘fucking’, 43), (‘aliens’, 43), (‘black’, 42), (‘government’, 41), (‘does’, 40), (‘man’, 39), (‘world’, 38), (‘come’, 38), (‘yes’, 38), (‘little’, 37), (‘head’, 37), (‘actually’, 37), (‘alex’, 37), (‘crazy’, 37), (‘talking’, 37), (‘try’, 36), (‘told’, 34), (‘love’, 33), (‘doesnt’, 33), (‘shit’, 33), (‘says’, 33), (‘kill’, 33), (‘ill’, 33), (‘life’, 32), (‘went’, 32), (‘true’, 31), (‘nazis’, 31), (‘everybody’, 31), (‘let’, 31), (‘war’, 31), (‘kind’, 31), (‘jones’, 30), (‘getting’, 30), (‘came’, 30), (‘telling’, 30), (‘understand’, 29), (‘control’, 29), (‘sure’, 28), (‘sandy’, 28)], ‘yang’: [(‘like’, 515), (‘people’, 190), (‘going’, 166), (‘know’, 134), (‘just’, 122), (‘thats’, 102), (‘im’, 84), (‘really’, 77), (‘say’, 69), (‘right’, 66), (‘youre’, 65), (‘theyre’, 64), (‘lot’, 63), (‘think’, 60), (‘actually’, 58), (‘make’, 56), (‘money’, 50), (‘dont’, 50), (‘job’, 46), (‘jobs’, 45), (‘mean’, 44), (‘look’, 43), (‘way’, 43), (‘things’, 42), (‘got’, 38), (‘time’, 38), (‘cuz’, 38), (‘theres’, 38), (‘truck’, 36), (‘thing’, 35), (‘years’, 35), (‘need’, 34), (‘start’, 34), (‘getting’, 34), (‘college’, 32), (‘new’, 31), (‘work’, 31), (‘month’, 27), (‘economy’, 26), (‘want’, 26), (‘doing’, 26), (‘idea’, 25), (‘man’, 24), (‘year’, 24), (‘president’, 24), (‘hey’, 24), (‘number’, 23), (‘thousand’, 23), (‘dollars’, 23), (‘try’, 22), (‘bucks’, 22), (‘states’, 22), (‘good’, 21), (‘trying’, 21), (‘trucks’, 21), (‘income’, 20), (‘robot’, 20), (‘coming’, 20), (‘basic’, 20), (‘problem’, 20), (‘joe’, 20), (‘great’, 19), (‘country’, 19), (‘saying’, 19), (‘stuff’, 19), (‘better’, 19), (‘said’, 19), (‘running’, 19), (‘real’, 19), (‘talking’, 18), (‘yeah’, 18), (‘universal’, 18), (‘americans’, 18), (‘million’, 18), (‘end’, 17), (‘school’, 17), (‘away’, 17), (‘making’, 17), (‘does’, 17), (‘truckers’, 16), (‘kids’, 16), (‘life’, 16), (‘reason’, 16), (‘ive’, 16), (‘economic’, 16), (‘sure’, 15), (‘numbers’, 15), (‘iowa’, 15), (‘cash’, 15), (‘rogan’, 15)],</p> </blockquote> <hr /> <h1 id="summary">Summary</h1> <h3 id="what-you-have-learned">What You have Learned</h3> <ul> <li>How to create and assign value to a variable</li> <li>How to create and assign values a list</li> <li>How to create and assign values a list of lists</li> <li>How to bring data into Python as text or csv files</li> <li>How to create and use a counter</li> <li>How to write a basic function</li> <li>How to call a basic function</li> <li>Basic loop structure - how to use for-loops</li> <li>How to import packages in Python</li> <li>How to use basic functions of packages like Pandas, Plotly, BeautifulSoup</li> <li>How to create interactive plots with Plotly.</li> </ul> </div> </article> <footer class="site-footer"> <div class="container"> <small class="block">&copy; 2019 ITL &middot; &lt;/&gt; Powered by <a href="https://jekyllrb.com/">Jekyll</a> and <a href="https://github.com/heiswayi/thinkspace">Thinkspace theme</a></small> </div> </footer> </main> <script type="text/javascript"> var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-XXXXX-XX']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> </body> </html>
